{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceca1f0d-9a43-4bd0-8b8e-85fccc5a04d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/programming/BME-574-2024`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7466ba6e-0bda-4ff5-ad69-35df0650106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaComputingRegistry.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/JuliaHubRegistry.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/programming/BME-574-2024/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Documents/programming/BME-574-2024/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add([\"Plots\",\"Distributions\",\"Random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3436c13d-cace-41b8-8117-a8292721f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Distributions, Random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5674ee3-ad83-4f8f-aa63-1a1a9ec73e78",
   "metadata": {},
   "source": [
    "A good measure for the floating point machine precision is the largest number that added to 1 results in 1.  This number is called $\\epsilon$. $1 + \\epsilon = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be98ff-dad7-4f27-abe7-be9f5612b708",
   "metadata": {},
   "source": [
    "We now would like to calculate the error of estimating the derivative by the finite difference method.\n",
    "In our example we calculate $\\frac{d}{dx}exp(x)$ at $x=1.0$ using the estimate\n",
    "\n",
    "$$\\frac{exp(1.0+\\Delta x)-exp(1.0)}{\\Delta x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95994a0c-8151-4812-917a-f84030bd59e5",
   "metadata": {},
   "source": [
    "The problem with finite differencing is that we are mixing our really small\n",
    "number with the really large number, and so when we do the subtract we lose\n",
    "accuracy. Instead, we want to keep the small perturbation completely separate.\n",
    "\n",
    "To see how to do this, assume that $x \\in \\mathbb{R}$ and assume that $f$ is\n",
    "complex analytic. You want to calculate a real derivative, but your function\n",
    "just happens to also be complex analytic when extended to the complex plane.\n",
    "Thus it has a Taylor series, and let's see what happens when we expand out this\n",
    "Taylor series purely in the complex direction:\n",
    "\n",
    "$$f(x+ih) = f(x) + f'(x)ih + \\mathcal{O}(h^2)$$\n",
    "\n",
    "which we can re-arrange as:\n",
    "\n",
    "$$if'(x) = \\frac{f(x+ih) - f(x)}{h} + \\mathcal{O}(h)$$\n",
    "\n",
    "Since $x$ is real and $f$ is real-valued on the reals, $if'$ is purely imaginary.\n",
    "So let's take the imaginary parts of both sides:\n",
    "\n",
    "$$f'(x) = \\frac{Im(f(x+ih))}{h} + \\mathcal{O}(h)$$\n",
    "\n",
    "since $Im(f(x)) = 0$ (since it's real valued!). Thus with a sufficiently small\n",
    "choice of $h$, this is the *complex step differentiation* formula for calculating\n",
    "the derivative.\n",
    "\n",
    "But to understand the computational advantage, recal that $x$ is pure real, and\n",
    "thus $x+ih$ is an imaginary number where **the $h$ never directly interacts with\n",
    "$x$** since a complex number is a two dimensional number where you keep the two\n",
    "pieces separate. Thus there is no numerical cancellation by using a small value\n",
    "of $h$, and thus, due to the relative precision of floating point numbers, both\n",
    "the real and imaginary parts will be computed to (approximately) 16 digits of\n",
    "accuracy for any choice of $h$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8a230-eadd-4434-87c2-4a10b0b1a3ee",
   "metadata": {},
   "source": [
    "## A different way of looking at derivatives\n",
    "\n",
    "The derivative measures the **sensitivity** of a function, i.e. how much the\n",
    "function output changes when the input changes by a small amount $\\epsilon$:\n",
    "\n",
    "$$f(a + \\epsilon) = f(a) + f'(a) \\epsilon + o(\\epsilon).$$\n",
    "\n",
    "In the following we will ignore higher-order terms; formally we set\n",
    "$\\epsilon^2 = 0$, which results in a nilpotent algebra.\n",
    "\n",
    "A function $f$ will be represented by its value $f(a)$ and derivative $f'(a)$,\n",
    "encoded as the coefficients of a degree-1 (Taylor) polynomial in $\\epsilon$:\n",
    "\n",
    "$$f \\rightsquigarrow f(a) + \\epsilon f'(a)$$\n",
    "\n",
    "Conversely, if we have such an expansion in $\\epsilon$ for a given function $f$,\n",
    "then we can identify the coefficient of $\\epsilon$ as the derivative of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13334c3c-2b54-46e4-a0e1-e42aadc053e4",
   "metadata": {},
   "source": [
    "## Dual numbers\n",
    "\n",
    "Thus, to extend the idea of complex step differentiation beyond complex analytic\n",
    "functions, we define a new number type, the *dual number*. A dual number is a\n",
    "multidimensional number where the sensitivity of the function is propagated\n",
    "along the dual portion.\n",
    "\n",
    "Here we will now start to use $\\epsilon$ as a dimensional signifier, like $i$,\n",
    "$j$, or $k$ for quaternion numbers. In order for this to work out, we need\n",
    "to derive an appropriate algebra for our numbers. To do this, we will look\n",
    "at Taylor series to make our algebra reconstruct differentiation.\n",
    "\n",
    "Note that the chain rule has been explicitly encoded in the derivative part.\n",
    "\n",
    "$$f(a + \\epsilon) = f(a) + \\epsilon f'(a)$$\n",
    "\n",
    "to first order. If we have two functions\n",
    "\n",
    "$$f \\rightsquigarrow f(a) + \\epsilon f'(a)$$\n",
    "$$g \\rightsquigarrow g(a) + \\epsilon g'(a)$$\n",
    "\n",
    "then we can manipulate these Taylor expansions to calculate combinations of\n",
    "these functions as follows. Using the nilpotent algebra, we have that:\n",
    "\n",
    "$$(f + g) = [f(a) + g(a)] + \\epsilon[f'(a) + g'(a)]$$\n",
    "\n",
    "$$(f \\cdot g) = [f(a) \\cdot g(a)] + \\epsilon[f(a) \\cdot g'(a) + g(a) \\cdot f'(a) ]$$\n",
    "\n",
    "From these we can *infer* the derivatives by taking the component of $\\epsilon$.\n",
    "These also tell us the way to implement these in the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8725eb2e-ccd2-4672-8a8b-04e90220dc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
